{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet18'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 111\n",
    "batch_size = 8\n",
    "img_size = (224, 224)\n",
    "\n",
    "datagen_args = dict(\n",
    "    rotation_range=5,\n",
    "    shear_range=10,\n",
    "    zoom_range=[1, 1.2],\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "image_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function=preprocess_input, \n",
    "    validation_split=0.2,\n",
    "    **datagen_args,\n",
    ")\n",
    "\n",
    "mask_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    **datagen_args\n",
    ")\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    './PaintDetectionDataset/train/images/', \n",
    "    class_mode=None, \n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    './PaintDetectionDataset/train/masks/',\n",
    "    class_mode=None, \n",
    "    color_mode='grayscale',\n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function=preprocess_input, \n",
    "    validation_split=0.2\n",
    ")\n",
    "mask_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_image_generator = image_datagen.flow_from_directory(\n",
    "    './PaintDetectionDataset/train/images/', \n",
    "    class_mode=None, \n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")\n",
    "val_mask_generator = mask_datagen.flow_from_directory(\n",
    "    './PaintDetectionDataset/train/masks/',\n",
    "    class_mode=None, \n",
    "    color_mode='grayscale',\n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 12, figsize=(32, 4))\n",
    "for i in range(12):\n",
    "    x = next(train_generator)\n",
    "    axs[0, i].imshow(x[0][0])\n",
    "    axs[1, i].imshow(x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def spe(y, batch_size):\n",
    "    return int(math.ceil((1. * y) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tensorflow.keras.optimizers.Adam(1e-5), loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"painting_segmentation.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=spe(186, batch_size), \n",
    "    validation_data=val_generator,\n",
    "    validation_steps=spe(46, batch_size),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, save=False, filepath=None):\n",
    "    x_plot = list(range(1, len(history[\"loss\"]) + 1))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.plot(x_plot, history[\"loss\"])\n",
    "    ax1.plot(x_plot, history[\"val_loss\"])\n",
    "    ax1.legend([\"Training\", \"Validation\"])\n",
    "\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"IOU\")\n",
    "    ax2.plot(x_plot, history[\"iou_score\"])\n",
    "    ax2.plot(x_plot, history[\"val_iou_score\"])\n",
    "    ax2.legend([\"Training\", \"Validation\"], loc=\"lower right\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if save and filepath is not None:\n",
    "        fig.savefig(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = './PaintDetectionDataset/test/images/img/*.jpg'\n",
    "\n",
    "fig, axes = plt.subplots(5, 10, sharex=True, sharey=True, figsize=(25, 8))\n",
    "\n",
    "paths = glob.glob(testdir)\n",
    "\n",
    "images = np.zeros((len(paths), 224, 224, 3))\n",
    "for i, img_path in enumerate(paths):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = preprocess_input(img)\n",
    "    images[i] = img\n",
    "\n",
    "preds = model.predict(images)\n",
    "\n",
    "for i in range(len(paths)):\n",
    "    mask = preds[i]\n",
    "    mask = (mask >= 0.5).astype(np.uint8)\n",
    "\n",
    "    k = i // 10\n",
    "    j = i % 10\n",
    "\n",
    "    axes[k, j].imshow(images[i])\n",
    "    axes[k, j].imshow(mask, 'jet', interpolation='none', alpha=0.7)\n",
    "    axes[k, j].axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f09894c958255dc4d5c5ddcaadfa6fd53a6bc0db9dbcfd2b866bd34deae996"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
