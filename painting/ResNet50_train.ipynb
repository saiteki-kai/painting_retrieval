{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWiPWcWBYbB9"
      },
      "source": [
        "# Fine Tuning of ResNet50\n",
        "\n",
        "We want to fine-tune ResNet50 to classify pictorial genres.\n",
        "\n",
        "We then want to save the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1lQNfBpXt6I"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "LzvyKaarSSOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "m-vFl7xrSVwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from keras.applications.resnet import ResNet50 \n",
        "from keras.applications.resnet import preprocess_input as preprocess_input_resnet\n",
        "from tensorflow.keras.preprocessing import image as image_resnet\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "UjvsG3FvA7nx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VT2vh22hXsig"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import itertools\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foJFcucihIuZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfrnRgOchQFZ",
        "outputId": "7e74e250-2b0b-418a-9d6b-e12fb1767b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ccie4hjlhIuZ"
      },
      "outputs": [],
      "source": [
        "base_dir = root_dir + '/Painting/data/'\n",
        "data_folder = base_dir + 'raw/dataset/'\n",
        "train_folder = data_folder + 'train/'\n",
        "test_folder = data_folder + 'test/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk_HXWV5aA0D"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset is taken by Kaggle at the following link: https://www.kaggle.com/c/painter-by-numbers/data ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biiykb7xhIub"
      },
      "source": [
        "We have to resize all the image to be (224,224) to be readable from VGG."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_cv2_image_resnet(image):\n",
        "  #image = cv.imread(image_path)\n",
        "  image = cv.resize(image, (224, 224))\n",
        "  image =  cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "  image = Image.fromarray(image)\n",
        "  image = image_resnet.img_to_array(image)\n",
        "  image = np.expand_dims(image, axis = 0)\n",
        "  return preprocess_input_resnet(image)"
      ],
      "metadata": {
        "id": "cKydBk8GDLbL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_folder + \"all_data_info.csv\")\n",
        "df.rename(columns={\"new_filename\": \"filename\"}, inplace=True)\n",
        "df.drop(columns=[\"pixelsx\", \"pixelsy\", \"size_bytes\", \"artist_group\", \"source\"], inplace=True)\n",
        "df.drop(columns=[\"artist\", \"style\", \"date\", \"title\"], inplace=True)\n",
        "df.dropna(subset=[\"genre\"], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# save memory \n",
        "df[\"genre\"] = df[\"genre\"].astype(\"category\")\n",
        "\n",
        "print(df.memory_usage(deep=True))\n",
        "print(df.info())\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.to_csv(data_folder + \"not_all_data_info.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etNgiYEyOXSV",
        "outputId": "89c495bc-6176-4687-820b-bce0d8b416f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index           128\n",
            "genre        105957\n",
            "in_train     101996\n",
            "filename    6723978\n",
            "dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 101996 entries, 0 to 101995\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype   \n",
            "---  ------    --------------   -----   \n",
            " 0   genre     101996 non-null  category\n",
            " 1   in_train  101996 non-null  bool    \n",
            " 2   filename  101996 non-null  object  \n",
            "dtypes: bool(1), category(1), object(1)\n",
            "memory usage: 997.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.expand_frame_repr', False)\n",
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tg74Nz3PCdN",
        "outputId": "0e96eb12-c0ca-4e24-9188-cb706ca07bbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['genre', 'in_train', 'filename'], dtype='object')\n",
            "                      genre  in_train    filename\n",
            "0                  abstract      True  102257.jpg\n",
            "1                  abstract      True   75232.jpg\n",
            "2     mythological painting      True   29855.jpg\n",
            "3                  abstract      True   62252.jpg\n",
            "4  bird-and-flower painting     False   49823.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_index(filename):\n",
        "  for index in range(df.shape[0]): #n_row\n",
        "    if( df[\"filename\"][index] == filename ):\n",
        "      return index\n",
        "  return -1"
      ],
      "metadata": {
        "id": "gP0j6AlAPmQ7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_genre_by_filename(filename):\n",
        "  index = get_image_index(filename)\n",
        "  return df[\"genre\"][index] "
      ],
      "metadata": {
        "id": "Mz5uyjThPSNL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images_from_folder(folder, save_folder_name):\n",
        "  save_folder = os.path.abspath(os.path.join(folder, os.pardir))\n",
        "  save_folder = os.path.join(save_folder, save_folder_name)\n",
        "\n",
        "  if not os.path.exists( save_folder ):\n",
        "    os.makedirs( save_folder )\n",
        "\n",
        "  N = len( os.listdir(folder) )\n",
        "  n_file = 0\n",
        "\n",
        "  for filename in os.listdir(folder):\n",
        "    img = cv.imread(os.path.join(folder,filename))\n",
        "    try:\n",
        "      img = preprocess_cv2_image_resnet(img)\n",
        "    except Exception as e:\n",
        "      print(str(e))\n",
        "      print(\"Problem with image: \" +filename)\n",
        "      img = None\n",
        "\n",
        "\n",
        "    if n_file % 10 == 0:\n",
        "      clear_output(wait=True)\n",
        "      print(\"{} / {} \" .format(n_file, N))\n",
        "    n_file = n_file + 1 \n",
        "\n",
        "    if img is not None:\n",
        "      index = get_image_index(filename)\n",
        "      if index != -1:\n",
        "        genre = df[\"genre\"][index]\n",
        "        temp_path = os.path.join(save_folder, genre)\n",
        "        if not os.path.exists( temp_path ):\n",
        "          os.makedirs( temp_path )\n",
        "        np.save( os.path.join(temp_path, filename), img)\n",
        "  \n",
        "  clear_output(wait=True)\n",
        "  print(\"{} / {} \" .format(N, N))\n",
        "  return True"
      ],
      "metadata": {
        "id": "EJyFIW6zQdEK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess_images_from_folder( train_folder, \"resized_train\")"
      ],
      "metadata": {
        "id": "Ku46sRrfQiNQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_images_from_folder( test_folder, \"resized_test\")"
      ],
      "metadata": {
        "id": "OwpEFYeHT9Ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25550720-2943-4d0a-8e8c-94a959d6b097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21410 / 23817 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(train_folder, \"resized_train\")\n",
        "test_dir = os.path.join(test_folder, \"resized_test\")"
      ],
      "metadata": {
        "id": "9065MIRiXud-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "24hnWiOAXj5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "num_classes = 42 #n_genre\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=input_shape,\n",
        "        color_mode='rgb',\n",
        "        batch_size=batch_size,\n",
        "        subset='training',\n",
        "        #class_mode='sparse'\n",
        "        )\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=input_shape,\n",
        "        color_mode='rgb',\n",
        "        batch_size=batch_size,\n",
        "        subset='validation',\n",
        "        #class_mode='sparse'\n",
        "        )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=input_shape,\n",
        "        color_mode='rgb',\n",
        "        batch_size=batch_size,\n",
        "        #class_mode='sparse'\n",
        "        )"
      ],
      "metadata": {
        "id": "ekP69saEW6Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaGQaBNesYgE"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)) )\n",
        "#base_model.summary()"
      ],
      "metadata": {
        "id": "60bwoV3sJoBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_model = base_model.output\n",
        "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
        "head_model = Flatten(name=\"flatten\")(head_model)\n",
        "head_model = Dense(256, activation=\"relu\")(head_model)\n",
        "head_model = Dropout(0.5)(head_model)\n",
        "head_model = Dense( num_classes , activation=\"softmax\")(head_model)"
      ],
      "metadata": {
        "id": "XBC8Ezf2Kzh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=head_model)\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "sdPm5XQ7LijS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "\tlayer.trainable = False"
      ],
      "metadata": {
        "id": "COef5zeRRuic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_micro = tfa.metrics.F1Score(num_classes=num_classes, average='micro')\n",
        "f1_macro = tfa.metrics.F1Score(num_classes=num_classes, average='macro')"
      ],
      "metadata": {
        "id": "LSb0odW7SHs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", #sparse_categorical_crossentropy\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\", f1_micro, f1_macro] )"
      ],
      "metadata": {
        "id": "RbQYSB6VR054"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "mwzXAX_faRXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train it on the data for some epochs\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "kOgvu4i0TWUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(data_folder + 'resnet_finetuing_model')"
      ],
      "metadata": {
        "id": "29-pgiN7VQ1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#x_plot = list(range(1,epochs+1))\n",
        "\n",
        "def plot_history(network_history):\n",
        "    epochs = len( history.history['loss'] )\n",
        "    x_plot = list(range(1,epochs+1))\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(x_plot, network_history.history['loss'])\n",
        "    plt.plot(x_plot, network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(x_plot, network_history.history['accuracy'])\n",
        "    plt.plot(x_plot, network_history.history['val_accuracy'])\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UDc6nB4vVdnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "6P6Lz8tzVfMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = model.evaluate(test_generator)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "id": "XcW6oDvoVgiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(test_generator)"
      ],
      "metadata": {
        "id": "KspU6yFgVhsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "for pred in test_pred:\n",
        "  y_pred.append( np.argmax(pred) )"
      ],
      "metadata": {
        "id": "QrCdtRMrVj2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_true = test_generator.labels\n",
        "\n",
        "f1_test = f1_score(y_true, y_pred, average='macro')\n",
        "print('Average f1_score: {} \\n' .format(f1_test) )\n",
        "\n",
        "print('F1-SCORE FOR EACH CLASS')\n",
        "print('-----------------------')\n",
        "av_f1_score = f1_score(y_true, y_pred, average=None)\n",
        "for i in range(len(av_f1_score)):\n",
        "  print('{} : {} '.format( i, av_f1_score[i]))"
      ],
      "metadata": {
        "id": "WuJ9ztlqVk3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay( confusion_matrix=cm )\n",
        "\n",
        "disp.plot()\n",
        "frame1 = plt.gca()\n",
        "frame1.axes.get_xaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sthzIJd7Vl_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ResNet50_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}