{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/ubuntu/Desktop/VISUAL/PaintDetectionDataset'\n",
    "train_path_images = os.path.join(data_folder, 'train/images')\n",
    "train_path_masks = os.path.join(data_folder, 'train/masks')\n",
    "\n",
    "test_path_images = os.path.join(data_folder, 'test/images')\n",
    "test_path_masks = os.path.join(data_folder, 'test/masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 111\n",
    "img_size = (224, 224)\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "lr = 1e-4\n",
    "BACKBONE = 'resnet34' #'vgg16'\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "datagen_args = dict(\n",
    "    rotation_range=5,\n",
    "    shear_range=10,\n",
    "    zoom_range=[1, 1.2],\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_image_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function=preprocess_input, \n",
    "    validation_split=0.2,\n",
    "    **datagen_args,\n",
    ")\n",
    "\n",
    "train_mask_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    **datagen_args\n",
    ")\n",
    "\n",
    "image_generator = train_image_datagen.flow_from_directory(\n",
    "    train_path_images, \n",
    "    class_mode=None, \n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "mask_generator = train_mask_datagen.flow_from_directory(\n",
    "    train_path_masks,\n",
    "    class_mode=None, \n",
    "    color_mode='grayscale',\n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    preprocessing_function=preprocess_input, \n",
    "    validation_split=0.2\n",
    ")\n",
    "val_mask_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_image_generator = val_image_datagen.flow_from_directory(\n",
    "    train_path_images, \n",
    "    class_mode=None, \n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")\n",
    "val_mask_generator = val_mask_datagen.flow_from_directory(\n",
    "    train_path_masks,\n",
    "    class_mode=None, \n",
    "    color_mode='grayscale',\n",
    "    seed=seed,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 12, figsize=(32, 4))\n",
    "for i in range(12):\n",
    "    x = next(train_generator)\n",
    "    axs[0, i].imshow(x[0][0])\n",
    "    axs[1, i].imshow(x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def spe(y, batch_size):\n",
    "    return int(math.ceil((1. * y) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tensorflow.keras.optimizers.Adam(lr), loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"painting_segmentation.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=spe(200, batch_size), \n",
    "    validation_data=val_generator,\n",
    "    validation_steps=spe(50, batch_size),\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, save=False, filepath=None):\n",
    "    x_plot = list(range(1, len(history[\"loss\"]) + 1))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.plot(x_plot, history[\"loss\"])\n",
    "    ax1.plot(x_plot, history[\"val_loss\"])\n",
    "    ax1.legend([\"Training\", \"Validation\"])\n",
    "\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"IOU\")\n",
    "    ax2.plot(x_plot, history[\"iou_score\"])\n",
    "    ax2.plot(x_plot, history[\"val_iou_score\"])\n",
    "    ax2.legend([\"Training\", \"Validation\"], loc=\"lower right\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if save and filepath is not None:\n",
    "        fig.savefig(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input,)\n",
    "test_mask_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "test_image_generator = test_image_datagen.flow_from_directory(\n",
    "    test_path_images, \n",
    "    class_mode=None, \n",
    "    seed=42,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "test_mask_generator = test_mask_datagen.flow_from_directory(\n",
    "    test_path_masks,\n",
    "    class_mode=None, \n",
    "    color_mode='grayscale',\n",
    "    seed=42,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_generator = zip(test_image_generator, test_mask_generator)\n",
    "loss, iou_score = model.evaluate(test_generator, steps=spe(50, batch_size), batch_size=batch_size)\n",
    "\n",
    "print('loss: {}, iou_score: {}'.format(loss, iou_score))\n",
    "\n",
    "# resnet34\n",
    "# train loss: 0.04106525331735611, iou_score: 0.9721957445144653\n",
    "# val loss: 0.0969313457608223, iou_score: 0.9506393074989319\n",
    "# test loss: 0.15183262526988983, iou_score: 0.9222055673599243\n",
    "\n",
    "# resnet18\n",
    "# train loss: 0.05787457153201103, iou_score: 0.9644907116889954\n",
    "# val loss: 0.08626668155193329, iou_score: 0.9521622657775879\n",
    "# test loss: 0.17578180134296417, iou_score: 0.915815532207489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 10, sharex=True, sharey=True, figsize=(25, 8))\n",
    "\n",
    "paths = glob.glob(os.path.join(test_path_images, 'img', '*.jpg'))\n",
    "\n",
    "images = np.zeros((len(paths), 224, 224, 3))\n",
    "for i, img_path in enumerate(paths):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = preprocess_input(img)\n",
    "    images[i] = img\n",
    "\n",
    "preds = model.predict(images)\n",
    "\n",
    "for i in range(len(paths)):\n",
    "    mask = preds[i]\n",
    "    mask = (mask >= 0.5).astype(np.uint8)\n",
    "\n",
    "    k = i // 10\n",
    "    j = i % 10\n",
    "\n",
    "    axes[k, j].imshow(images[i])\n",
    "    axes[k, j].imshow(mask, 'jet', interpolation='none', alpha=0.7)\n",
    "    axes[k, j].axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f09894c958255dc4d5c5ddcaadfa6fd53a6bc0db9dbcfd2b866bd34deae996"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
